I'm only familiar with some of the applications on the IBM cloud platform so my answer would be limited to what I'm familiar using. I would prepare different Python scripts to use with Apache Airflow for automating the ETL step. I can also use a Python script to upload the new data to the IBM cloud storage. IBM also has a BI platform which can connect to the cloud storage which can be used to create the company's BI solutions. Since there are other cloud platform options we can use, there are plenty of factors that would affect the final choice for the data solutions. There is a should be a balance of cost, connectivity, security, scalability, and others which would need to be considered to for the final pipeline design.